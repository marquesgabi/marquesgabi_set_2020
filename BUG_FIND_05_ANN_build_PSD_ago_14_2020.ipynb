{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BUG_FIND_05_ANN_build_PSD_ago_14_2020.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ucfilho/marquesgabi_set_2020/blob/master/BUG_FIND_05_ANN_build_PSD_ago_14_2020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sog7Z9pyhUD_"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import numpy as np\n",
        "import cv2\n",
        "import zipfile\n",
        "from random import randint\n",
        "from PIL import Image\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "#import scikit-image\n",
        "import skimage\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ne27Oa8E66fS",
        "outputId": "7b17fb9d-5049-4024-c284-029bf2189af2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "!pip install mahotas"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mahotas in /usr/local/lib/python3.6/dist-packages (1.4.11)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from mahotas) (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYo6yMKOjiJQ"
      },
      "source": [
        "# Import the 'transform' module from 'skimage'\n",
        "from skimage import transform "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "La6dFeJujmZM"
      },
      "source": [
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mOm3AQvCUp3"
      },
      "source": [
        "# 03_ANN_NEW_DATA... only the grains in 882 are used for training \n",
        "#                    the ANN and segmented images are used to \n",
        "#                    train no-grain"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMDoD-W9CVol"
      },
      "source": [
        "# 03_ANN_NEW_DATA... only the grains in 882 are used for training the ANN and segmented images are used to train no-grain"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJAZpHlAi6Vq",
        "outputId": "1dd87d96-e527-421d-894c-a15ddfc5e6e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "!git clone https://github.com/ucfilho/marquesgabi_Julho_2020_using\n",
        "%cd marquesgabi_Julho_2020_using\n",
        "Transfere='FotosTreino882_and_Segm.zip'\n",
        "file_name = zipfile.ZipFile(Transfere, 'r')\n",
        "file_name.extractall()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'marquesgabi_Julho_2020_using' already exists and is not an empty directory.\n",
            "/content/marquesgabi_Julho_2020_using\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYx5ot9RrYYt"
      },
      "source": [
        "# First step: get the segmented file (photos stored in csv file)\n",
        "\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8Bl70iLs7FF"
      },
      "source": [
        "# First step: get the segmented file (photos stored in csv file)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C35MvO7VjUA0"
      },
      "source": [
        "labels = [] #name files\n",
        "\n",
        "with zipfile.ZipFile(Transfere, \"r\") as f:\n",
        "  for f in f.namelist():\n",
        "    labels.append(f)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuDx6iA-w0aW"
      },
      "source": [
        "Num=len(labels)\n",
        "df=pd.read_csv(labels[0])\n",
        "for i in range(1,Num):\n",
        "  df_new=pd.read_csv(labels[i])\n",
        "  df_new = df_new[~df_new['Type'].isin(['G'])] # drop grain row which is not in 882\n",
        "  frames = [df, df_new]\n",
        "  df= pd.concat(frames, ignore_index=True)\n",
        "\n",
        "y_valor=df['Type']"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuwLJl-21LQt",
        "outputId": "ce49103b-8367-4a92-baa5-deed108d2b41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "print(df)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     Unnamed: 0 Type          0  ...        782        783  Width\n",
            "0             0    G    0.00000  ...    0.68631    0.68769    NaN\n",
            "1             1    G    0.00000  ...    0.49262    0.50909    NaN\n",
            "2             2    G    0.45321  ...    0.54919    0.55439    NaN\n",
            "3             3    G    0.75367  ...    0.48524    0.61876    NaN\n",
            "4             4    G    0.94521  ...    0.98108    0.95838    NaN\n",
            "..          ...  ...        ...  ...        ...        ...    ...\n",
            "976           7    B   84.33883  ...    7.14600    7.38484  142.0\n",
            "977           8    I  104.73698  ...    2.05457    0.38150  163.0\n",
            "978           9    I   75.70248  ...  107.38844  106.00001  154.0\n",
            "979          10    I   56.64465  ...    3.15316    0.40107  187.0\n",
            "980          11    B  111.50165  ...    0.00000    0.00000  194.0\n",
            "\n",
            "[981 rows x 787 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwELp2Lv1NKY",
        "outputId": "f24e96e8-7ea5-4d5a-e214-5d17fe4b1810",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "print(df.head())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Unnamed: 0 Type        0        1  ...      781      782      783  Width\n",
            "0           0    G  0.00000  0.00000  ...  0.68642  0.68631  0.68769    NaN\n",
            "1           1    G  0.00000  0.00000  ...  0.47277  0.49262  0.50909    NaN\n",
            "2           2    G  0.45321  0.52257  ...  0.54645  0.54919  0.55439    NaN\n",
            "3           3    G  0.75367  0.64590  ...  0.43356  0.48524  0.61876    NaN\n",
            "4           4    G  0.94521  0.89736  ...  0.98942  0.98108  0.95838    NaN\n",
            "\n",
            "[5 rows x 787 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMCpdgC91ON0",
        "outputId": "d560ed06-f720-4469-e363-5a88ceba3057",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "print(df)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     Unnamed: 0 Type          0  ...        782        783  Width\n",
            "0             0    G    0.00000  ...    0.68631    0.68769    NaN\n",
            "1             1    G    0.00000  ...    0.49262    0.50909    NaN\n",
            "2             2    G    0.45321  ...    0.54919    0.55439    NaN\n",
            "3             3    G    0.75367  ...    0.48524    0.61876    NaN\n",
            "4             4    G    0.94521  ...    0.98108    0.95838    NaN\n",
            "..          ...  ...        ...  ...        ...        ...    ...\n",
            "976           7    B   84.33883  ...    7.14600    7.38484  142.0\n",
            "977           8    I  104.73698  ...    2.05457    0.38150  163.0\n",
            "978           9    I   75.70248  ...  107.38844  106.00001  154.0\n",
            "979          10    I   56.64465  ...    3.15316    0.40107  187.0\n",
            "980          11    B  111.50165  ...    0.00000    0.00000  194.0\n",
            "\n",
            "[981 rows x 787 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wq1CSlXUhjEv",
        "outputId": "9e91888c-d01a-45c6-d0cb-74ccd6e75f93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "df_teste=pd.read_csv(labels[2])\n",
        "print(df_teste.head())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Unnamed: 0  Width Type          0  ...       780       781        782        783\n",
            "0           0    157    I   71.90012  ...  49.57118  35.95513    7.75954    1.03862\n",
            "1           1    124    I  127.06763  ...  94.57544  98.71695  100.52861  100.84391\n",
            "2           2    182    G   87.10651  ...   5.33136   5.84024    5.89941    5.65089\n",
            "3           3    101    I   99.01176  ...  35.15087  41.39006   43.76875   44.09146\n",
            "4           4    183    I   56.30844  ...  52.96656  53.65711   53.44656   53.11703\n",
            "\n",
            "[5 rows x 787 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkMXproqxZig",
        "outputId": "7f119b7e-bc2f-4671-e4d6-acf23143da20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "print(df.tail())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     Unnamed: 0 Type          0  ...        782        783  Width\n",
            "976           7    B   84.33883  ...    7.14600    7.38484  142.0\n",
            "977           8    I  104.73698  ...    2.05457    0.38150  163.0\n",
            "978           9    I   75.70248  ...  107.38844  106.00001  154.0\n",
            "979          10    I   56.64465  ...    3.15316    0.40107  187.0\n",
            "980          11    B  111.50165  ...    0.00000    0.00000  194.0\n",
            "\n",
            "[5 rows x 787 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpuIGIU-pkiG"
      },
      "source": [
        "Fotos=df.drop(['Unnamed: 0','Type','Width'], axis=1)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYpsqk8iqOG2"
      },
      "source": [
        "df=df.drop(['Unnamed: 0','Type','Width'], axis=1)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfXvfb-n9LPp",
        "outputId": "bec83438-4486-4304-e0e7-a189ea2b917d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "print(df.describe())"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                0           1           2  ...         781         782         783\n",
            "count  981.000000  981.000000  981.000000  ...  981.000000  981.000000  981.000000\n",
            "mean     7.834253    7.847765    7.784539  ...    5.294938    5.215285    5.291887\n",
            "std     23.507544   23.434137   23.360003  ...   18.945649   19.327633   19.863527\n",
            "min      0.000000    0.000000    0.000000  ...    0.000000    0.000000    0.000000\n",
            "25%      0.311510    0.309190    0.313200  ...    0.332510    0.336190    0.329620\n",
            "50%      0.499150    0.490170    0.490990  ...    0.483030    0.479810    0.489680\n",
            "75%      0.640190    0.644030    0.652580  ...    0.639650    0.640320    0.637210\n",
            "max    127.067630  126.206040  120.224750  ...  108.437500  114.958580  121.952670\n",
            "\n",
            "[8 rows x 784 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2PqY2SbzFI2",
        "outputId": "8a367b5d-a1ba-4e33-8a5b-717801ec8b63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(np.array(Fotos).shape )"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(981, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDoUMG4vsmoa"
      },
      "source": [
        "# Second step: create the ann to evaluate which is a grain in photos segmented\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlX05oVmx3cY"
      },
      "source": [
        "# only crop photos teach what is grain...."
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biuEDBlM4H_J"
      },
      "source": [
        "images28=np.array(df)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1FNc_PgKZ3o"
      },
      "source": [
        "#print(y_valor)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgZ5KNGh8mzN"
      },
      "source": [
        "y_new=[]\n",
        "Grain=0\n",
        "Others=0\n",
        "Cont=-1\n",
        "Others_Local=[]\n",
        "Grain_Local=[]\n",
        "for x in y_valor:\n",
        "  Cont=Cont+1\n",
        "  if re.search('G', x):\n",
        "    y_new.append(1)\n",
        "    Grain=Grain+1\n",
        "    Grain_Local.append(Cont)\n",
        "  else:\n",
        "    y_new.append(2)\n",
        "    Others=Others+1\n",
        "    Others_Local.append(Cont)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4IZyKSa_Xvv",
        "outputId": "4170aacd-5700-44f8-980b-977d11849868",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "print('Graos=',Grain)\n",
        "print('Others=',Others)\n",
        "print('Others local',Others_Local)\n",
        "print('Grain local',Grain_Local)\n",
        "\n",
        "sampled_list = random.sample(Others_Local,Grain)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Graos= 245\n",
            "Others= 736\n",
            "Others local [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980]\n",
            "Grain local [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 36, 37, 38, 39, 40, 41, 42, 43, 72, 73, 74, 75, 76, 108, 109, 110, 111, 112, 113, 114, 144, 145, 146, 147, 148, 149, 170, 171, 172, 173, 206, 207, 208, 209, 210, 211, 212, 213, 242, 243, 244, 245, 246, 247, 248, 249, 268, 269, 270, 271, 272, 273, 274, 275, 276, 304, 305, 306, 307, 308, 309, 310, 340, 341, 342, 343, 344, 345, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 402, 403, 404, 405, 406, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 500, 501, 502, 503, 504, 505, 506, 507, 508, 536, 537, 538, 539, 540, 541, 542, 543, 544, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 588, 589, 590, 591, 592, 593, 594, 624, 625, 626, 627, 628, 629, 630, 631, 632, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 696, 697, 698, 699, 700, 701, 702, 703, 704, 732, 733, 734, 735, 736, 737, 738, 739, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 820, 821, 822, 823, 824, 825, 826, 827, 828, 856, 857, 858, 859, 860, 861, 862, 863]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvRB2ROqCgc6",
        "outputId": "d709a90a-c695-4492-d166-d994b3224b34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "print('Graos=',Grain)\n",
        "print('Others=',Others)\n",
        "print('Others local',Others_Local)\n",
        "sampled_list = random.sample(Others_Local,Grain)\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Graos= 245\n",
            "Others= 736\n",
            "Others local [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgjoSbt0Chl-",
        "outputId": "7e533b04-9bb3-42fc-eda1-80e2e1559d29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "print('Graos=',Grain)\n",
        "print('Others=',Others)\n",
        "print('Others local',Others_Local)\n",
        "print('Grain local',Grain_Local)\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Graos= 245\n",
            "Others= 736\n",
            "Others local [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980]\n",
            "Grain local [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 36, 37, 38, 39, 40, 41, 42, 43, 72, 73, 74, 75, 76, 108, 109, 110, 111, 112, 113, 114, 144, 145, 146, 147, 148, 149, 170, 171, 172, 173, 206, 207, 208, 209, 210, 211, 212, 213, 242, 243, 244, 245, 246, 247, 248, 249, 268, 269, 270, 271, 272, 273, 274, 275, 276, 304, 305, 306, 307, 308, 309, 310, 340, 341, 342, 343, 344, 345, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 402, 403, 404, 405, 406, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 500, 501, 502, 503, 504, 505, 506, 507, 508, 536, 537, 538, 539, 540, 541, 542, 543, 544, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 588, 589, 590, 591, 592, 593, 594, 624, 625, 626, 627, 628, 629, 630, 631, 632, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 696, 697, 698, 699, 700, 701, 702, 703, 704, 732, 733, 734, 735, 736, 737, 738, 739, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 820, 821, 822, 823, 824, 825, 826, 827, 828, 856, 857, 858, 859, 860, 861, 862, 863]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkM-s9TiCyLt"
      },
      "source": [
        "x_new=[]\n",
        "y_rede=[]\n",
        "for i in range(Grain):\n",
        "  x_new.append(Fotos.iloc[Grain_Local[i]])\n",
        "  x_new.append(Fotos.iloc[sampled_list[i]])\n",
        "  y_rede.append(y_new[Grain_Local[i]])\n",
        "  y_rede.append(y_new[sampled_list[i]])\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qHR83qhGa0G",
        "outputId": "ae012d44-eeb1-47bb-e244-c81c7c4c1591",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "np.array(x_new).shape"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(490, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZp3WDdEFu3I"
      },
      "source": [
        "#pd.DataFrame(y_rede).describe()"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nb33el9Y9AXG"
      },
      "source": [
        "# y_valor=np.copy(y_new)\n",
        "y_total=np.copy(y_rede)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSs3qh0_uO94"
      },
      "source": [
        "#Define data train and data test\n",
        "#images28=Fotos\n",
        "images28=x_new #Fotos\n",
        "W_train, W_test, yw_train, yw_test = train_test_split(np.array(images28), np.array(y_total), \n",
        "                                                    test_size=0.30, shuffle=True, \n",
        "                                                    random_state=42)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGzcVt8V0ft2",
        "outputId": "5f3fd001-0b61-4648-8c15-56183ce8d3b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "print(len(y_total))\n",
        "print(len(yw_test))\n",
        "print(len(yw_train))\n",
        "A=490*0.3\n",
        "print(A)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "490\n",
            "147\n",
            "343\n",
            "147.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwHcagDGuow0"
      },
      "source": [
        "train_images=W_train #imagens utilizadas para o treino\n",
        "train_labels=yw_train # resposta esperada para o treino\n",
        "test_images=W_test\n",
        "test_labels=yw_test"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEblnmBlsTMc"
      },
      "source": [
        "#print(len(test_labels))"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWSEclzGurul"
      },
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dense(10)\n",
        "])"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w88iZqfVusm0"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0MAtbvxuwQE",
        "outputId": "acd727a7-1fb1-462d-a51d-e6a053dba9d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# GRAIN use crop photos other cases segmented\n",
        "model.fit(train_images, train_labels, epochs=200) "
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input Tensor(\"flatten_input:0\", shape=(None, 28, 28), dtype=float32), but it was called on an input with incompatible shape (None, 784).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input Tensor(\"flatten_input:0\", shape=(None, 28, 28), dtype=float32), but it was called on an input with incompatible shape (None, 784).\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 2.4267 - accuracy: 0.4840 \n",
            "Epoch 2/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 1.9432 - accuracy: 0.5102\n",
            "Epoch 3/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 1.0667 - accuracy: 0.5248\n",
            "Epoch 4/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 1.1118 - accuracy: 0.5073\n",
            "Epoch 5/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.7785 - accuracy: 0.5364\n",
            "Epoch 6/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.9113 - accuracy: 0.5773\n",
            "Epoch 7/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 1.1299 - accuracy: 0.5277\n",
            "Epoch 8/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.9310 - accuracy: 0.6297\n",
            "Epoch 9/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.8888 - accuracy: 0.5569\n",
            "Epoch 10/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.7208 - accuracy: 0.6939\n",
            "Epoch 11/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 1.1494 - accuracy: 0.5248\n",
            "Epoch 12/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.5842 - accuracy: 0.6997\n",
            "Epoch 13/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.9795 - accuracy: 0.5685\n",
            "Epoch 14/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.5700 - accuracy: 0.6939\n",
            "Epoch 15/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 1.0548 - accuracy: 0.5773\n",
            "Epoch 16/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 1.3568 - accuracy: 0.5452\n",
            "Epoch 17/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.8749 - accuracy: 0.6880\n",
            "Epoch 18/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 1.7441 - accuracy: 0.5452\n",
            "Epoch 19/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 1.9312 - accuracy: 0.5219\n",
            "Epoch 20/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.5733 - accuracy: 0.6968\n",
            "Epoch 21/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.8066 - accuracy: 0.6589\n",
            "Epoch 22/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.8253 - accuracy: 0.6327\n",
            "Epoch 23/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7201\n",
            "Epoch 24/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4748 - accuracy: 0.7522\n",
            "Epoch 25/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.7755\n",
            "Epoch 26/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.7930\n",
            "Epoch 27/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.7813\n",
            "Epoch 28/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4407 - accuracy: 0.7959\n",
            "Epoch 29/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4362 - accuracy: 0.8017\n",
            "Epoch 30/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7843\n",
            "Epoch 31/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.7843\n",
            "Epoch 32/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.7872\n",
            "Epoch 33/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.8076\n",
            "Epoch 34/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.7959\n",
            "Epoch 35/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4198 - accuracy: 0.7959\n",
            "Epoch 36/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4210 - accuracy: 0.8192\n",
            "Epoch 37/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4159 - accuracy: 0.8076\n",
            "Epoch 38/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4149 - accuracy: 0.8017\n",
            "Epoch 39/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4121 - accuracy: 0.8047\n",
            "Epoch 40/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4147 - accuracy: 0.8192\n",
            "Epoch 41/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4101 - accuracy: 0.8163\n",
            "Epoch 42/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4061 - accuracy: 0.8280\n",
            "Epoch 43/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4028 - accuracy: 0.8192\n",
            "Epoch 44/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4047 - accuracy: 0.8222\n",
            "Epoch 45/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4028 - accuracy: 0.8134\n",
            "Epoch 46/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3975 - accuracy: 0.8280\n",
            "Epoch 47/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3971 - accuracy: 0.8222\n",
            "Epoch 48/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3969 - accuracy: 0.8280\n",
            "Epoch 49/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3932 - accuracy: 0.8280\n",
            "Epoch 50/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3929 - accuracy: 0.8309\n",
            "Epoch 51/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3886 - accuracy: 0.8367\n",
            "Epoch 52/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3860 - accuracy: 0.8309\n",
            "Epoch 53/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3840 - accuracy: 0.8426\n",
            "Epoch 54/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3828 - accuracy: 0.8367\n",
            "Epoch 55/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3816 - accuracy: 0.8367\n",
            "Epoch 56/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3799 - accuracy: 0.8367\n",
            "Epoch 57/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.3785 - accuracy: 0.8251\n",
            "Epoch 58/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3762 - accuracy: 0.8367\n",
            "Epoch 59/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3758 - accuracy: 0.8484\n",
            "Epoch 60/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3747 - accuracy: 0.8251\n",
            "Epoch 61/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3700 - accuracy: 0.8397\n",
            "Epoch 62/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3718 - accuracy: 0.8484\n",
            "Epoch 63/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3723 - accuracy: 0.8309\n",
            "Epoch 64/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3750 - accuracy: 0.8426\n",
            "Epoch 65/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3661 - accuracy: 0.8484\n",
            "Epoch 66/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3652 - accuracy: 0.8309\n",
            "Epoch 67/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3628 - accuracy: 0.8542\n",
            "Epoch 68/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3668 - accuracy: 0.8397\n",
            "Epoch 69/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3613 - accuracy: 0.8397\n",
            "Epoch 70/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3573 - accuracy: 0.8484\n",
            "Epoch 71/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3575 - accuracy: 0.8542\n",
            "Epoch 72/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3554 - accuracy: 0.8513\n",
            "Epoch 73/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3551 - accuracy: 0.8513\n",
            "Epoch 74/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3537 - accuracy: 0.8542\n",
            "Epoch 75/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3536 - accuracy: 0.8484\n",
            "Epoch 76/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3491 - accuracy: 0.8601\n",
            "Epoch 77/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3487 - accuracy: 0.8571\n",
            "Epoch 78/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3520 - accuracy: 0.8455\n",
            "Epoch 79/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3481 - accuracy: 0.8630\n",
            "Epoch 80/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3508 - accuracy: 0.8513\n",
            "Epoch 81/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3433 - accuracy: 0.8659\n",
            "Epoch 82/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3431 - accuracy: 0.8630\n",
            "Epoch 83/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3434 - accuracy: 0.8601\n",
            "Epoch 84/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3446 - accuracy: 0.8484\n",
            "Epoch 85/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3440 - accuracy: 0.8542\n",
            "Epoch 86/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3370 - accuracy: 0.8542\n",
            "Epoch 87/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3396 - accuracy: 0.8542\n",
            "Epoch 88/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3426 - accuracy: 0.8601\n",
            "Epoch 89/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3449 - accuracy: 0.8542\n",
            "Epoch 90/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3344 - accuracy: 0.8513\n",
            "Epoch 91/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3328 - accuracy: 0.8746\n",
            "Epoch 92/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.3295 - accuracy: 0.8630\n",
            "Epoch 93/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3292 - accuracy: 0.8513\n",
            "Epoch 94/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 2.0595 - accuracy: 0.6676\n",
            "Epoch 95/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 2.9718 - accuracy: 0.5277\n",
            "Epoch 96/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.6713 - accuracy: 0.7085\n",
            "Epoch 97/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.9449 - accuracy: 0.6560\n",
            "Epoch 98/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.5741 - accuracy: 0.7668\n",
            "Epoch 99/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.6803 - accuracy: 0.6997\n",
            "Epoch 100/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.7959\n",
            "Epoch 101/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3776 - accuracy: 0.8280\n",
            "Epoch 102/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3714 - accuracy: 0.8251\n",
            "Epoch 103/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3602 - accuracy: 0.8455\n",
            "Epoch 104/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3523 - accuracy: 0.8455\n",
            "Epoch 105/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3458 - accuracy: 0.8484\n",
            "Epoch 106/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.3469 - accuracy: 0.8426\n",
            "Epoch 107/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3437 - accuracy: 0.8601\n",
            "Epoch 108/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3447 - accuracy: 0.8571\n",
            "Epoch 109/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3446 - accuracy: 0.8601\n",
            "Epoch 110/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3418 - accuracy: 0.8513\n",
            "Epoch 111/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3382 - accuracy: 0.8630\n",
            "Epoch 112/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3397 - accuracy: 0.8601\n",
            "Epoch 113/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3366 - accuracy: 0.8630\n",
            "Epoch 114/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3366 - accuracy: 0.8601\n",
            "Epoch 115/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3325 - accuracy: 0.8571\n",
            "Epoch 116/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3324 - accuracy: 0.8630\n",
            "Epoch 117/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8630\n",
            "Epoch 118/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3295 - accuracy: 0.8601\n",
            "Epoch 119/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3319 - accuracy: 0.8659\n",
            "Epoch 120/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8630\n",
            "Epoch 121/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3261 - accuracy: 0.8601\n",
            "Epoch 122/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3277 - accuracy: 0.8688\n",
            "Epoch 123/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3272 - accuracy: 0.8601\n",
            "Epoch 124/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3242 - accuracy: 0.8688\n",
            "Epoch 125/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3223 - accuracy: 0.8688\n",
            "Epoch 126/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3206 - accuracy: 0.8688\n",
            "Epoch 127/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3236 - accuracy: 0.8659\n",
            "Epoch 128/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3205 - accuracy: 0.8571\n",
            "Epoch 129/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.3218 - accuracy: 0.8717\n",
            "Epoch 130/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3181 - accuracy: 0.8601\n",
            "Epoch 131/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3157 - accuracy: 0.8717\n",
            "Epoch 132/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3167 - accuracy: 0.8659\n",
            "Epoch 133/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3232 - accuracy: 0.8426\n",
            "Epoch 134/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3128 - accuracy: 0.8659\n",
            "Epoch 135/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3154 - accuracy: 0.8688\n",
            "Epoch 136/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3099 - accuracy: 0.8717\n",
            "Epoch 137/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3113 - accuracy: 0.8688\n",
            "Epoch 138/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3089 - accuracy: 0.8659\n",
            "Epoch 139/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3102 - accuracy: 0.8659\n",
            "Epoch 140/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3107 - accuracy: 0.8717\n",
            "Epoch 141/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3052 - accuracy: 0.8659\n",
            "Epoch 142/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3070 - accuracy: 0.8746\n",
            "Epoch 143/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3098 - accuracy: 0.8659\n",
            "Epoch 144/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3014 - accuracy: 0.8776\n",
            "Epoch 145/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3051 - accuracy: 0.8717\n",
            "Epoch 146/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3049 - accuracy: 0.8717\n",
            "Epoch 147/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3001 - accuracy: 0.8688\n",
            "Epoch 148/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2993 - accuracy: 0.8746\n",
            "Epoch 149/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2986 - accuracy: 0.8776\n",
            "Epoch 150/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3014 - accuracy: 0.8717\n",
            "Epoch 151/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2994 - accuracy: 0.8776\n",
            "Epoch 152/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2963 - accuracy: 0.8776\n",
            "Epoch 153/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2955 - accuracy: 0.8776\n",
            "Epoch 154/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2957 - accuracy: 0.8776\n",
            "Epoch 155/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2936 - accuracy: 0.8805\n",
            "Epoch 156/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2911 - accuracy: 0.8805\n",
            "Epoch 157/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2968 - accuracy: 0.8746\n",
            "Epoch 158/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2922 - accuracy: 0.8776\n",
            "Epoch 159/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2893 - accuracy: 0.8834\n",
            "Epoch 160/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2903 - accuracy: 0.8834\n",
            "Epoch 161/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.2947 - accuracy: 0.8805\n",
            "Epoch 162/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2889 - accuracy: 0.8863\n",
            "Epoch 163/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.2864 - accuracy: 0.8834\n",
            "Epoch 164/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2932 - accuracy: 0.8834\n",
            "Epoch 165/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2936 - accuracy: 0.8688\n",
            "Epoch 166/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2928 - accuracy: 0.8921\n",
            "Epoch 167/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2916 - accuracy: 0.8688\n",
            "Epoch 168/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2910 - accuracy: 0.8863\n",
            "Epoch 169/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2854 - accuracy: 0.8805\n",
            "Epoch 170/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2818 - accuracy: 0.8863\n",
            "Epoch 171/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2813 - accuracy: 0.8892\n",
            "Epoch 172/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2794 - accuracy: 0.8892\n",
            "Epoch 173/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2837 - accuracy: 0.8805\n",
            "Epoch 174/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2805 - accuracy: 0.8805\n",
            "Epoch 175/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2764 - accuracy: 0.8863\n",
            "Epoch 176/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2754 - accuracy: 0.8863\n",
            "Epoch 177/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2742 - accuracy: 0.8892\n",
            "Epoch 178/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2771 - accuracy: 0.8892\n",
            "Epoch 179/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2906 - accuracy: 0.8950\n",
            "Epoch 180/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2747 - accuracy: 0.8980\n",
            "Epoch 181/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2731 - accuracy: 0.8921\n",
            "Epoch 182/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2716 - accuracy: 0.8863\n",
            "Epoch 183/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2719 - accuracy: 0.8892\n",
            "Epoch 184/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2729 - accuracy: 0.8805\n",
            "Epoch 185/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2682 - accuracy: 0.8980\n",
            "Epoch 186/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2699 - accuracy: 0.8892\n",
            "Epoch 187/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2711 - accuracy: 0.8921\n",
            "Epoch 188/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2703 - accuracy: 0.8892\n",
            "Epoch 189/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2659 - accuracy: 0.8980\n",
            "Epoch 190/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2652 - accuracy: 0.8921\n",
            "Epoch 191/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2683 - accuracy: 0.8863\n",
            "Epoch 192/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2613 - accuracy: 0.8980\n",
            "Epoch 193/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2735 - accuracy: 0.8892\n",
            "Epoch 194/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.7757 - accuracy: 0.7055\n",
            "Epoch 195/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 1.2578 - accuracy: 0.7143\n",
            "Epoch 196/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 1.0750 - accuracy: 0.7055\n",
            "Epoch 197/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 2.5514 - accuracy: 0.5569\n",
            "Epoch 198/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 1.0125 - accuracy: 0.7522\n",
            "Epoch 199/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 3.8526 - accuracy: 0.5248\n",
            "Epoch 200/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 1.7132 - accuracy: 0.6356\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2ea74cd198>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0BTZBnKuy5p"
      },
      "source": [
        "#ANN das imagens\n",
        "x=np.array(W_test)\n",
        "logits = model(x, training=False)\n",
        "prediction = tf.argmax(logits, axis=1, output_type=tf.int32)\n",
        "#print(prediction)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRYwCufJyyTI",
        "outputId": "bcdca97a-71af-4488-8013-9459e4e5664e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "print(x)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.62516 0.67814 0.7257  ... 0.34312 0.32268 0.31357]\n",
            " [0.52206 0.51394 0.51079 ... 0.75293 0.64692 0.61091]\n",
            " [0.15494 0.1429  0.13764 ... 0.15702 0.08283 0.09974]\n",
            " ...\n",
            " [0.57714 0.53188 0.59974 ... 0.34552 0.35858 0.32893]\n",
            " [0.5801  0.59905 0.64345 ... 0.44491 0.43344 0.44076]\n",
            " [0.00784 0.00784 0.00784 ... 0.40255 0.43726 0.43929]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wU-3mMSMu6a6"
      },
      "source": [
        "y_valor=np.copy(yw_test)\n",
        "data = {'y_Actual': y_valor,\n",
        "        'y_Predicted': prediction\n",
        "        }  # este dado esta no formato de dicionario\n",
        "\n",
        "df = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])\n",
        "#print (df)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u48SDVPavRwS",
        "outputId": "47a02f62-934f-4a31-d6eb-07ac1618175c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "confusion_matrix = pd.crosstab(df['y_Actual'], df['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])\n",
        "print(confusion_matrix)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted   1   2\n",
            "Actual           \n",
            "1          63  14\n",
            "2          17  53\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyU1PG434y8F",
        "outputId": "84e026c3-3ae1-41e4-8ce4-b68c69238b35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "y_true = df['y_Actual']\n",
        "y_pred = df['y_Predicted']\n",
        "print(sklearn.metrics.classification_report(y_true, y_pred))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.79      0.82      0.80        77\n",
            "           2       0.79      0.76      0.77        70\n",
            "\n",
            "    accuracy                           0.79       147\n",
            "   macro avg       0.79      0.79      0.79       147\n",
            "weighted avg       0.79      0.79      0.79       147\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiD6Nl-JHqvu"
      },
      "source": [
        "#"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3UfvtMqHzxM"
      },
      "source": [
        "# Third step: testing ANN other segmented images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MN7tnJfjHIdo",
        "outputId": "6ac86781-6912-42b0-82ae-c193e9d3a7a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "!git clone https://github.com/ucfilho/marquesgabi_August_2020\n",
        "%cd marquesgabi_August_2020"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'marquesgabi_August_2020' already exists and is not an empty directory.\n",
            "/content/marquesgabi_Julho_2020_using/marquesgabi_August_2020\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMdkCzS5HkG_"
      },
      "source": [
        "Transfere='img28_all00.zip'\n",
        "file_name = zipfile.ZipFile(Transfere, 'r')\n",
        "file_name.extractall()"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9WiyyRrMTHX"
      },
      "source": [
        "labels = [] #name files\n",
        "\n",
        "with zipfile.ZipFile(Transfere, \"r\") as f:\n",
        "  for f in f.namelist():\n",
        "    labels.append(f)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MM9nDQtwsq4",
        "outputId": "cd1882ca-d421-4ef0-f1b1-deac05734132",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "df=pd.read_csv(labels[0])\n",
        "print(df.shape)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(150, 787)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxWbtaIEKsSg",
        "outputId": "47bdfdb1-b2a2-49cf-ba52-bd1788965553",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "df=pd.read_csv(labels[0])\n",
        "Width_All=df['Width']\n",
        "df=df.drop(['Unnamed: 0','Type','Width'], axis=1)\n",
        "print(df.head())"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "          0         1         2  ...        781       782       783\n",
            "0  61.14508  60.20605  63.89233  ...   87.26298  86.56084  70.53898\n",
            "1  54.96550  56.12730  56.46103  ...    6.09697   6.10529   6.17609\n",
            "2  81.32749  86.75936  93.59119  ...  104.26302  98.95892  98.95303\n",
            "3   0.39589   0.51145   0.68329  ...   60.38241  58.77369  57.35922\n",
            "4  48.26560  49.34269  51.20098  ...   86.94305  86.16422  92.14825\n",
            "\n",
            "[5 rows x 784 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4f7NjosMyYG"
      },
      "source": [
        "# Fourth step test ANN for data to be used for PSD (Particle size distribution) determination"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqQ2_G5_5KhB"
      },
      "source": [
        "# Mahotas used: marquesgabi_fev_2020/02_Mahotas_fracionado_fev_20_2020.ipynb"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNesWgX1-gqp",
        "outputId": "7a683b00-7f07-4fc6-8cc8-21d4ea753947",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "!git clone https://github.com/ucfilho/marquesgabi_fev_2020 #clonar do Github\n",
        "%cd marquesgabi_fev_2020"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'marquesgabi_fev_2020' already exists and is not an empty directory.\n",
            "/content/marquesgabi_Julho_2020_using/marquesgabi_August_2020/marquesgabi_fev_2020\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAjAyirk5XtD"
      },
      "source": [
        "import mahotas.features.texture as mht\n",
        "import mahotas.features\n",
        "from skimage import filters\n",
        "from skimage import exposure\n",
        "import skimage.feature as sk\n",
        "from google.colab import files\n",
        "from numpy import linalg as LA\n",
        "from scipy import stats\n",
        "from scipy.signal import find_peaks\n",
        "from scipy.signal import peak_prominences\n",
        "from scipy.signal import peak_widths\n",
        "from scipy import integrate\n",
        "import re\n",
        "import Go2BlackWhite\n",
        "import Go2Mahotas"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3ktDsN-851A"
      },
      "source": [
        "\n",
        "Escolha=['ASM', 'constrast', 'correl', 'variance', 'inv diff mom', 'sum aveg', \n",
        "         'sum var', 'sum entropy', 'entropy', 'dif var', 'dif entropy', \n",
        "         'IMC1', 'IMC2']\n",
        "\n",
        "Prop=Escolha[1] # Propriedade a escolher para ter picos, largura de pico, proeminencia,..."
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_BbzDjxPjaS"
      },
      "source": [
        "#ANN das imagens\n",
        "x=np.array(df)\n",
        "logits = model(x, training=False)\n",
        "prediction = tf.argmax(logits, axis=1, output_type=tf.int32)\n",
        "#print(prediction)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Z8keSNCQLCu",
        "outputId": "cb889dff-d4a3-42f9-f0ab-65d3186d861c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "y=np.array(prediction)\n",
        "Num=len(y)\n",
        "print(Num)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "150\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeI5CgqMVIy_",
        "outputId": "868f7557-18b0-4c6c-a219-d2d06516497b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "print(y)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 1 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 1\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 1 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFxdeNNzQylf",
        "outputId": "99a36d40-2179-4a1a-879f-3755a295ab09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "# select just the grains to show picture\n",
        "grain=[]\n",
        "Mahotas_Prop=[]\n",
        "Todas_Fotos=[] \n",
        "\n",
        "img28_all=pd.DataFrame(x)\n",
        "\n",
        "print('*****oooooo*****oooooo***')\n",
        "print(Width_Grain_2)\n",
        "print(rows)\n",
        "print('*****oooooo*****oooooo***')\n",
        "print(gwl)\n",
        "\n",
        "Width_Grain_2=[]\n",
        "\n",
        "Size=28 # tamanho da foto\n",
        "Sub_Size=int(Size/5) # tamanho do fracionamento\n",
        "Row_Crop=1/2 # posicao do corte\n",
        "#Row_Crop=1/3 # posicao do corte\n",
        "Crop=int(Size*Row_Crop)\n",
        "\n",
        "\n",
        "for i in range(Num):\n",
        "  if(y[i]==1):\n",
        "    grain.append(i)\n",
        "    Width_Grain_2.append(Width_All[i])\n",
        "\n",
        "cont=0 # \n",
        "cols=5\n",
        "rows=int(len(grain)/cols)+1\n",
        "Grao_in_All28=[]\n",
        "\n",
        "print('*****oooooo*****oooooo***')\n",
        "print(Width_Grain_2)\n",
        "print(rows)\n",
        "print('*****oooooo*****oooooo***')\n",
        "print(gwl)\n",
        "\n",
        "for i in range(Num):\n",
        "  if(y[i]==1):\n",
        "    Grao_in_All28.append(i)\n",
        "    cont=cont+1\n",
        "    plt.subplot(rows,cols,cont) # subplot not allow cont=0\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    Foto=np.array(img28_all.iloc[i]).reshape(28,28)\n",
        "    plt.imshow(Foto, cmap = \"gray\")\n",
        "    plt.xlabel(i)\n",
        "\n",
        "    Prop_Escolhida=[]\n",
        "    \n",
        "    # p_foto=ww[k].reshape(Size,Size)\n",
        "    p_foto=Foto\n",
        "    GLCM=[]\n",
        "    glcm_haralick=[]\n",
        "    x_ref=[]\n",
        "    Count=Sub_Size\n",
        "    p=np.zeros((Sub_Size,Sub_Size))\n",
        "    j_ref=0\n",
        "    Cada_foto=[]\n",
        "    Posicao_X=[]\n",
        "    Posicao_Y=[]\n",
        "    for k in range(Size):\n",
        "      if((k+Sub_Size-1)<Size):\n",
        "        #print(\"(k+Sub_Size)=\",(k+Sub_Size),\"k=\",k)\n",
        "        for i in range(Sub_Size):\n",
        "          Posicao_X.append(Crop+i)\n",
        "          for j in range(Sub_Size):\n",
        "            p[i,j]=p_foto[Crop+i,j+k]\n",
        "            Posicao_Y.append(j+k)\n",
        "\n",
        "        WW=np.copy(p)\n",
        "\n",
        "        Cada_foto.append(WW.ravel())\n",
        "        x_ref.append(Count-Sub_Size)\n",
        "        Count=Count+1\n",
        "      \n",
        "        Mahotas =pd.DataFrame(mahotas.features.haralick(p.astype(int)), columns =Escolha)\n",
        "        Prop_Escolhida.append(Mahotas[Prop].mean())\n",
        "\n",
        "    Todas_Fotos.append(Prop_Escolhida)\n",
        "\n",
        "df_mahotas=pd.DataFrame(Todas_Fotos)\n",
        "\n",
        "plt.subplots_adjust(bottom=0.1, right=1.2, top=2,hspace=0.3, wspace=0.1)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*****oooooo*****oooooo***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-5a11c9281a88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'*****oooooo*****oooooo***'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWidth_Grain_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'*****oooooo*****oooooo***'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Width_Grain_2' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eYPwWpXwBLw"
      },
      "source": [
        "print('====*******======')\n",
        "print(df_mahotas)\n",
        "print('================')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoxCjN_dI-zp"
      },
      "source": [
        "Features_Total=[]\n",
        "cont=-1\n",
        "for i in range(Num):\n",
        "  if(y[i]==1):\n",
        "    cont=cont+1\n",
        "    x_psd=df_mahotas.iloc[cont]\n",
        "    peaks, rr = find_peaks(x_psd, height=0)\n",
        "\n",
        "    N_peaks=len(peaks)\n",
        "    prominences = peak_prominences(x_psd, peaks)\n",
        "    \n",
        "    #Area = simps(x, dx=1)\n",
        "    Area = integrate.simps(x_psd, dx=1)\n",
        "    if(len(peaks)==0):\n",
        "      Width_peaks =0\n",
        "      Width_peaks_max =0\n",
        "      Width_peaks_min =0\n",
        "      Media_proem=0    \n",
        "    else:\n",
        "      Width_peaks =np.mean(peak_widths(x_psd, peaks, rel_height=0.5))\n",
        "      Width_peaks_max =np.max(peak_widths(x_psd, peaks, rel_height=0.5))\n",
        "      Width_peaks_min =np.min(peak_widths(x_psd, peaks, rel_height=0.5))\n",
        "      Media_proem=np.mean(prominences)\n",
        "    Median = np.median(x_psd)\n",
        "    Mode= stats.mode(x_psd)[0]\n",
        "    Mean=np.mean(x_psd)\n",
        "    Sd=np.std(x_psd)\n",
        "\n",
        "    Features=[]\n",
        "    Features.append(N_peaks)\n",
        "    Features.append(Media_proem )\n",
        "    Features.append(Area)\n",
        "    Features.append(Width_peaks )\n",
        "    Features.append(Width_peaks_max)\n",
        "    Features.append(Width_peaks_min)\n",
        "    Features.append(Median )\n",
        "    Features.append(Mode[0])\n",
        "    Features.append(Mean)\n",
        "    Features.append(Sd)\n",
        "\n",
        "    Features_Total.append(Features)\n",
        "\n",
        "Nomes_PSD=['N_peaks','Media_proem','Area','Width_peaks','Width_peaks_max',\n",
        "                    'Width_peaks_min','Median','Mode','Mean','Sd'] \n",
        "  \n",
        "Features_Total=pd.DataFrame(Features_Total,columns=Nomes_PSD)\n",
        "    \n",
        "print(Features_Total)\n",
        "# Features_total represents properties without considering there is no class \n",
        "# Features_total describes all grains found by the ANN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNA12S8qtmZW"
      },
      "source": [
        "print('==============')\n",
        "print(Features_Total)\n",
        "print('==============')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JU2tWkqICxsn"
      },
      "source": [
        "rows=1;cols=2\n",
        "k=8\n",
        "plt.subplot(rows,cols,1)\n",
        "plt.plot(df_mahotas.iloc[k])\n",
        "Foto=np.array(img28_all.iloc[Grao_in_All28[k]]).reshape(28,28)\n",
        "plt.subplot(rows,cols,2)\n",
        "plt.imshow(Foto, cmap = \"gray\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1mMdsBdtCxF"
      },
      "source": [
        "print(Width_Grain_2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdLe_4CpYgQK"
      },
      "source": [
        "Width_Grain=Width_All.iloc[grain]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuv-ZqzBO5gG"
      },
      "source": [
        "Width_Grain=np.array(Width_Grain) # passando de Serie (dataframe 1d) para np.array\n",
        "print(Width_Grain) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiaxgbsoO3nB"
      },
      "source": [
        "print(Width_Grain_2) # lista : tem virgula entre os elementos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbBBcNo46AWy"
      },
      "source": [
        "# Fifth step create classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7j23MjtE57Gt"
      },
      "source": [
        "Width_bounds=[100,200]\n",
        "N_Class=4\n",
        "Class=[]\n",
        "a=Width_bounds[0]\n",
        "b=Width_bounds[1]\n",
        "delta_ab=(b-a)/N_Class\n",
        "for i in range(N_Class-1):\n",
        "  valor=a+delta_ab*(i+1)\n",
        "  Class.append(valor)\n",
        "\n",
        "print(Class)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qf-sX8qd6s8L"
      },
      "source": [
        "Num=len(Width_Grain)\n",
        "count=[0,0,0,0]\n",
        "Hist_Width=[]\n",
        "for i in range(Num):\n",
        "  if(Width_Grain[i]<Class[0]):\n",
        "    count[0]=count[0]+1\n",
        "    Hist_Width.append(0)\n",
        "  elif(Width_Grain[i]<Class[1]):\n",
        "    count[1]=count[1]+1\n",
        "    Hist_Width.append(1)\n",
        "  elif(Width_Grain[i]<Class[2]):\n",
        "    count[2]=count[2]+1\n",
        "    Hist_Width.append(2)\n",
        "  else:\n",
        "    count[3]=count[3]+1\n",
        "    Hist_Width.append(3)\n",
        "\n",
        "print(count)\n",
        "N_count=np.copy(count)\n",
        "\n",
        "Nomes_class=['until_w1','w1-w2','w2-w3','bigger-w3']+Nomes_PSD"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6QhlSI5Z3wB"
      },
      "source": [
        "print(Hist_Width)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmNgEFpJdpeK"
      },
      "source": [
        "print(Features_Total.iloc[0,1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSxUsRTVdTdi"
      },
      "source": [
        "rows=len(Width_Grain)\n",
        "cols=len(Nomes_PSD)\n",
        "Features_Class=np.zeros((4,cols)) # matrix containing average values stored. Each line is reprenting a different class\n",
        "\n",
        "for i in range(rows):\n",
        "  k=Hist_Width[i]\n",
        "  for j in range(cols):  \n",
        "    Features_Class[k,j]=Features_Class[k,j]+ Features_Total.iloc[i,j]\n",
        "\n",
        "print(pd.DataFrame(Features_Class,columns=Nomes_PSD))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g11B8SyJio6J"
      },
      "source": [
        "for i in range(4):\n",
        "  if(N_count[i]==0):\n",
        "    fator=0\n",
        "  else:\n",
        "    fator=1/N_count[i]\n",
        "  Features_Class[i,:]=Features_Class[i,:]*fator\n",
        "print(pd.DataFrame(Features_Class,columns=Nomes_PSD))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZnP1WyTjBJS"
      },
      "source": [
        "print(N_count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnoYTsonie7J"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}